{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chat with Video"
      ],
      "metadata": {
        "id": "ekTh00NOFnOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example we're going to work through building a \"chat-with-video\" AI pipeline. We'll see how to:\n",
        "\n",
        "1. Take any YouTube video and transcribe it to text using Aurelio's video-to-text endpoint.\n",
        "2. Use Mistral LLMs to chat with our transcribed video content.\n",
        "3. Add chat history to make our AI conversational.\n",
        "4. Integrate async and streaming for a better UX and improved scalability.\n",
        "5. See how we can optimize response latency and costs by reducing overall token count using semantic similarity, using Aurelio's chunking endpoint and Mistral's embedding models."
      ],
      "metadata": {
        "id": "yJf8rvVIFnl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \\\n",
        "  aurelio-sdk==0.0.18 \\\n",
        "  \"yt-dlp[default]==2025.2.19\" \\\n",
        "  mistralai==1.5.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hc3OuwuNmaRb",
        "outputId": "0bd4cadb-e7e7-4d41-947a-c913a6e6a0b8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.9/171.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.3/278.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yt-dlp https://www.youtube.com/watch?v=JaHfCrVTYF4 -f mp4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsD7-ytckdTr",
        "outputId": "9f0ff5c7-7773-446d-91df-cc404b6d3590"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=JaHfCrVTYF4\n",
            "[youtube] JaHfCrVTYF4: Downloading webpage\n",
            "[youtube] JaHfCrVTYF4: Downloading tv client config\n",
            "[youtube] JaHfCrVTYF4: Downloading player f6e09c70\n",
            "[youtube] JaHfCrVTYF4: Downloading tv player API JSON\n",
            "[youtube] JaHfCrVTYF4: Downloading ios player API JSON\n",
            "[youtube] JaHfCrVTYF4: Downloading m3u8 information\n",
            "[info] JaHfCrVTYF4: Downloading 1 format(s): 18\n",
            "[download] Destination: AI Agents as Neuro-Symbolic Systems？ [JaHfCrVTYF4].mp4\n",
            "\u001b[K[download] 100% of   57.40MiB in \u001b[1;37m00:00:04\u001b[0m at \u001b[0;32m13.68MiB/s\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the [Aurelio Platform](https://platform.aurelio.ai/) for both video processing _and_ later for chunking. To follow the tutorial you can use the coupon `JBVIDEOAGENT` for free credits."
      ],
      "metadata": {
        "id": "salkxHIostF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from aurelio_sdk import AurelioClient\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"AURELIO_API_KEY\"] = os.getenv(\"AURELIO_API_KEY\") or getpass(\"Enter your Aurelio API key: \")\n",
        "\n",
        "client = AurelioClient(api_key=os.environ[\"AURELIO_API_KEY\"])"
      ],
      "metadata": {
        "id": "sleO9IX0myXj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we send our video to Aurelio Platform for processing and chunking:"
      ],
      "metadata": {
        "id": "EaVuNZy9msnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response_video_file = client.extract_file(\n",
        "    file_path=\"/content/AI Agents as Neuro-Symbolic Systems？ [JaHfCrVTYF4].mp4\",\n",
        "    quality=\"low\", chunk=False, wait=-1\n",
        ")"
      ],
      "metadata": {
        "id": "h8w7CLXknrD0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can access the transcribed video like so:"
      ],
      "metadata": {
        "id": "erJAXpbVeiRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content = response_video_file.document.content\n",
        "content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "omo2FI_HrdRA",
        "outputId": "3b4fbf15-c0f5-442e-da48-ac451af5dc02"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Okay, so I wanted to put together a sort of overview video of what I'm currently working on, which is thinking or restructuring the way that I'm thinking about agents and the way that I'm also teaching or talking about agents. So this isn't going to be like a fully sort of edited and structured video. I just want to show you a little bit of what I'm thinking about and explain or explain where I'm coming from really.  So all in all, this is part of actually a broader thing that I am working on, which is actually why I haven't been posting on YouTube specifically for quite a while. And I think it's almost two months, which is the longest I think I haven't posted in forever. And, you know, it's well, okay, it's because I'm working on this, but it's also for other things as well. I had my first son like a month ago. So I've been pretty busy there. and just working on a lot of things over Aurelio as well. But I wanted to go through this introduction to  AI agents article that I'm working on. And it's done, but I do want to put together a more structured video and some sort of course details on this. There's even a already a code example for this, which is just taking a look at the React agent, which obviously I wanted it earlier. Not earlier, it's probably, I would say, like the foundational structure for what a, agents look like today? Or when I say agents, I mean LM-based agents.  And I think, well, that is just the most popular type of agent. Okay, React, now it's more like tools or tool agents, but they're very similar. Anyway, I'll talk a little bit about them. So the first thing I do want to maybe cover very quickly is the React agent, because that's what we're most familiar with. So I'll come down to here. So as a reminder, okay, React is basically this. here. So we have some input, okay, some types. And rather than just  asking our LLM to answer directly, we allow our LLM to go through multiple reasoning steps. And part of those reasoning steps is the fact that the agent can also call tools. So it can get some external information or do something else. And that's what I'm visualizing here, right? So we have our question. This is from the React paper, which I have linked to. But the example is, okay, aside from the Apple remote, what other device can control the program Apple remote was originally designed to interact with. Probably, to be honest, most ALM can answer this directly now, I think.  particularly given that the this example is from the React paper which is like two years ago but anyway soft topic we're just giving an example here right so in this example what we're doing is okay we have these tools that the LM can use we provide them and we're also prompting the agent the LM sorry to say okay go through these multiple steps of reasoning and action so that is where the React comes from so it's RE and act from action. And it goes through these steps. So it's like, okay, I have access to the search tool.  And like an answer tool at the bottom here, which not really at all, but it kind of is at the same time. So it goes through, has this prompt, and it knows I have to structure things in this React methodology. So that's what it does. It says, okay, it starts. It says, okay, I need to search Apple remote and find a program is used for, and then it provides its structures an action based on that. So it knows it has a search tool and it knows that the input to the search tool is a query, which is a string. So we have the app or remote. That function runs using some logic we've developed.  And the observation from that is this. The Apple Remote is designed to control the front row media center. Okay. So what was the question? We have aside from the Apple Remote what other device can control the program Apple Remote was originally decided to interact with. So now we know what that original program was, right, which is front row. And we have that information. The LM now knows that information. So it goes on to a next second. It says, okay, what do I need to do now? I know that Apple remote controls the front row program.  but what other device controls the front row program. So it says, okay, based on this, my next reasoning step is I need to search front row and find other devices that control it. So then it does this search for front row. It could also probably do something, if we're thinking in rag terms here, it could be like device to control front row. And probably more today LM would do that. But that's fine. this is just an example. So it goes back to the search tool again and it says query. Front row. And this isn't  I've shortened this for the sake of brevity. I think in the actual example, or at least from the paper, the actual example returns a lot more information. But this is the part of it that is important. The front row is controlled by an Apple remote or keyboard function keys. Okay, so now we know that. That gets fed back into the LM. So the LM now knows everything that we've covered here, knows the original query. And now it's like, okay, well, I have all the information that I need to answer the original query which is site to a map or remote what other device can control front row  So the next step is the LM is like, oh, okay, I have everything. I can now provide the answer of keyboard function keys to the user. Okay. And so it doesn't use a search tool. Now it instead uses the answer tool, which has this query, this, sorry, parameter out. And the answer or the output for that is keyboard function keys, which then gets provided back to the user. that. Okay. So this is the React agent and this sort of structure of like reasoning, building  a like a query for a tool, getting a response, and then potentially going through another iteration of reasoning and action and another and then eventually providing an answer. That is really the sort of commonly accept a definition of what an agent is. That's what most people are using at the moment. And I think that is great, but I think it's very limiting. because I just wouldn't, in production, I would never just put something like this, whether it's React or Open AI tools or whatever else.  I wouldn't just put that. In my opinion, an agent is much broader than just what this is. And also in general, broader literature, an agent is not just this either. So I went back and I just went through a few papers trying to figure out, okay, what is the actual good definition of an agent that kind of makes sense in the way that I also understand the agents, the way that I've been building like agentic, more workflows to be honest, right? But to me, workflow or agent is kind of  Same thing. It's agentic workflow, i.e. agent. So, anyway, I went back and the paper that I think had the nicest definition that tied back to really like original, like, AI, well, philosophy, like the original AI philosophy or the original AI research, maybe not original, but pretty close to original, and I don't think maybe original, was this, right? So it was a miracle paper, right, which is another...  basically agent, LM agent. I think this came just before the React agent paper. It's very similar, I would say, has a bit less structured in the React agent. But, yeah, it's super relevant. And the way that they described their system was that it was a neurosymbolic architecture. I really like this definition because a, so neurosymbolic architecture, It's two things, right? You have the neural part, you have the symbolic part. And I actually have another kind of starting  on this article but it's uh yeah there's this mostly notes at the moment so the neural part of this in fact let's start with the symbolic part the symbolic part is the more traditional AI right so the you know I think this is back in the 40s 50s 60s mostly and then maybe so actually 70s as well this was actually maybe not 70s this was this was a the sort of traditional approach to AI. And the idea,  or the symbolists that were just like full on symbolists felt that true AGI would be achieved through written rules, ontologies and these other logical functions to basically a load of handwritten stuff, like smart, like philosophical grammars. An example of this is the, I think it's syllogistic logic from Aristotle. and the, so basically, an example of this would be a, I think it's got,  you have this major premise then you have a minor premise and i haven't done this for a long time so forgive me if i'm not super accurate um but you have a major premise minor premise and conclusion based on that so the idea is like if you say something like um all all dogs have four legs which is maybe not actually true but let's just assume that you like all dogs have four legs by nature. Okay.  So let's just remove that bit. Let's not be too pedantic. All dogs have four legs, right? That is your major premise. Then you would say, um, my friend, Japs is a dog. Okay? Your conclusion would be, okay, um, my friend Japs has, has four laps. Okay, so this is a logical framework developed by Arisothel.  And the symbolic AI people would, you know, do things like these, these sort of exercises where they're going through all this and trying to build up some sort of logical methodology to allow you to kind of construct some deeper, like aGI type system where it can just kind of figure everything out. Now, that was like one side of AI back then. And this is like the traditional AI, it's also called like good,  old fashioned AI. I don't remember who or when that was turned, but gofi. I don't know if they actually call it gofi, but that's how it's written. And yeah, I mean, that was one camp. The other camp were the connectionists. So this is what we, we call them back then. Now it's kind of the neural AI type thing. So connectionism was in, so kind of emerged back in 9. there was this basically a paper that described a neural circuit.  But really, the where neural or connectionist AI really started with is with this guy, Rosenblatt, who introduced this idea of a perceptron. And it's actually the perceptron is in an adapted version of the perceptron that he described is what we use in neural networks today. So it was, okay, now it's a big deal. But back then, they were less useful, but a lot of people really believed in it. And they were probably,  at least so far, they were more correct, I would say. Now, the connectionist's approach is focused on building AI systems loosely based on the mechanisms of our brains. So neural network, perceptron is just like a kind of silly name. Now we would say things like neurons within the neural network. They all have these sort of names, right? Whereas you can tell they're kind of coming from the idea of a brain. I don't have an example here, but you can see, okay,  have a look at in Google. This is the perception, right? And then if you look at a sort of a neuron diagram, if that's a thing, activation, you know, kind of, there's something, right? So here you have a, like an actual neuron diagram. And you can see there's a lot of similarity. I think this one, they're probably comparing it to an actual neuron in the sort of AI sense. Actually, here is  is a perfect example. Let me make this bigger. No. Right. So this is a good example. On the left, you have all these inputs, basically for your neuron in your brain. Goes through some kind of calculation, which in this case is the axon. And then you have all these outputs. And this is actually many outputs, but you can think of them as kind of similar in some way. Because all of these axons here, to be fair, I think they have different degrees. degrees of activation. But when you get your  output here, you just have sort of one output. So I suppose in some degree this would be different. But just when you look at a single neural network neuron, obviously we put many of these in many layers and then at that point you have many sort of axons, although each one is just coming from a single output here. But any case, there is definitely a lot of similarity here. So yeah, anyway, that is kind of, you know, one fundamental.  building blocks of neural AI. And yeah, for neural AI to work in a lot of compute, parallel processing, all this sort of stuff. And because of that, it didn't really kick off. And there was a few like AI, what we call AI winters, where people were just less interested in AI in general, but particularly the neural or connectionist AI. And yeah, I mean, that kind of carried on into, into the future until we got towards like 2011, 2012 where you had image net and  the, what is it called, the AlexNet model. And they sort of kicked off interest in neural or connectionist AI again. And at that point, it's just like neural networks. Everyone's like, wow, neural networks are amazing. And we still think that. That's what transformers and LLMs and their core building block is, well, they are a type of neural network. Just more kind of big and complicated. Anyway, so that kicked off because we had loads of data and compute and everything and  And yeah, it led to where we are now, right? So that's what the neural part is, and that's also what the symbolic part is here. Right? So, okay, what do we have here? We have both. We're mixing the old traditional AI with neural AI. Well, kind of. To some degree, they are almost kind of mixed together already with neural networks, because neural networks, the way that they work, they almost learn symbols, like they learn logical representations of different concepts, which is what the symbol,  part is in some symbolic they learn these right but they're just not handwritten okay so you know neural network kind of learns what are what a strawberry is or what a dog is but anyway it's kind of side the point um we can just assume okay maybe maybe neural networks are subs symbolic but for now let's just assume they're purely symbolic that's fine so neural networks make up the neural part of this so basically LLMs, then we have this symbolic part. The symbolic part, as I mentioned before, it's handwritten stuff, right? So...  like code. So if you write some like some code that can be run by a or triggered by an LLM or some other type of neural network that you have some sort of neural's neuro symbolic architecture. You have a mix of both. So that's that is what they that is right and when they develop the miracle system here they're using I think it's like GPD to no maybe but jubtie 3 um but like the first version of it which was not that great and then they were  with so this was actually their sort of agent system but I think they built at least part of this on top of an I'm not sure if it was open source model I don't remember the name of it to be honest for the life of me but anyway it doesn't matter so so they basically built this agentic type thing by mixing neural networks with runable code yeah and then and then you actually see some of the things that they're talking about here are you know kind of and the things that we try and solve with rag in many cases, lack of up-to-date knowledge, like proprietary knowledge,  all these sort of things, which is kind of interesting, I think. But anyway, so my definition of agents kind of goes along those lines. It's neural plus symbolic. And the reason I like it is one, we have that sort of, that definition is anchored in, you know, the AI for the past almost 100 years, maybe 8. 80 years roughly, which is great. I think it's good that we have some like really, very, very  solid foundations behind that definition, neuro-symbolic. And two, one of the reasons I like it is because when I'm building these systems, okay, LMs are great, but I don't just use LLMs. A lot of time, there is very good reason to bring in other neural network-based models. So by broadening that neural definition to neural network, you don't restrict yourself to just saying LLM, right?  hey, use our limbs, like amazing. And of course, I use them a lot, but not just our lamps, right? So the idea behind, if I go to semantic router, I don't know if you've used it, not a big deal if you haven't. But the idea behind semantic router, let me find an image instead. Actually, maybe I have an introduction here. Wow, we don't have an introduction. Okay. Okay, so this is a better  example or easy to explain an example. So semantic router uses embedding models, which are on neural network based. And what they do is you have some text. I have a better image somewhere. Let me find it. Okay, so this is the other example. So we have an embedding model, the thing in the middle here. And what we do is we provide some example inputs. So it's like political route, just this is more for like a guard rail right so this would be a this would be an actual guard rail here as you know  like protection basically and okay that's fine whatever that that is just one example then we have the ask lm route and this is a better example so s lm route all right so i'm saying okay what is the lama 2 model llama 3 now i wrote this a long time ago tell me about metas new lm what are the differences between falcon and llama right all of those are obviously things i want to trigger a search right so what I can do is I can I can identify this with the embedding model so I can say okay anything that gets caught in this little area here  anything caught in that area there, that is probably the user asking for us to do a search, essentially. So then what we can do, what is many things we can do, but one thing we can just do is say, okay, that's the user query, just send it straight across to some rag pipeline, right? So don't even ask the LLM, don't even ask an LM to rephrase it or, you know, make a decision to use the RAD pipeline, just use the Rite pipeline directly. and it's way faster than going through an LM and I would say probably much more controllable. However,  LMs provide a lot of flexibility. So that's not what I would usually do. Instead, what I usually do is there's still an LM, right? So let's say over here, right? I have an LM. And what I do is, okay, we have our query that we got from the user. What I'm gonna do is I'm just gonna, I'm gonna modify it a little bit. All right, so I'm gonna come over here. And this is just like, kind of lazy way, It works well and it leaves the flexibility of use down to the LLM, which I like.  So I say, okay, original query right from the user. So whatever that was, so we have the query. And then I append something extra. So I say, like system note is something I've used fairly often before. And I'll just say use the rag tool. Okay. I don't like this new. Maybe that is a nice fun. It's fine. Whatever, I'm using this one now. Right. So I modified it. query that gets sent to the LM. And in the LM, you're basically kind of heavily suggesting to the LM and what it should do, and that works actually very well. So this sort of system, the agent is not just the LLM, it's also the embedding here, right? And especially if you're not even including an LLM here. There's, to me, this system without an LLM is pretty agentic to me, right? That seems to me to be an agent. And then even more so when you add the LLM and decision-making in there. So, yeah, I.  I prefer to think of agents as this type of system, right? Or not just this type of system, but at least more flexibly. Because I think that if you think of agents just as an LLM that can call tools, you're massively limiting, you know, you're boxing yourself into this one thing that an agent may be. Whereas I think that's kind of a stupid thing to do. and even if you take the example of, okay, let's say we have multiple like tool sets or we have, okay, once we've this  decided on one tool. Okay, let's start here. Right. Let's say we make a decision. Now, LM is making this decision. That's fine. No problem. Right, but it goes down these two different paths. All right. So it says tool A or tool B. And let's say if we have used tool A for, you know, whatever that is, maybe it's reading about the news. Whereas tool B is, oh, it's someone's asking a math question so you know that it's like a calculator or it's actually maybe it's searching for some explanation from like a like a math website right where is this going to a news website, right? Two different use cases. And what you might find with these two different use cases is that the follow-on tools, if any, right? Maybe there aren't any, who knows, right? But maybe there are. And the follow-on tools for these would be different, right? I mean, you've already identified that the intent is very, you know, is two very different things. So why would the follow-on tools be similar? There's no reason for them to be. So in this case, right? So you may still have an LM in the middle, maybe. Maybe sometimes you won't.  you would then, you know, follow this slightly different path, right? And if you're, if you're thinking of agents as just, oh, it's a LM plus some tool calls in a loop, right? You already, this is fairly simple and you can't do it. So my, yeah, that's what I'm thinking about with agents. That's how I would approach them, which is slightly different to, I think, what, like what the, the standard sort of narrative is from most people on what an agent is, right?  So, okay, it's valid, but it's not all that an agent is. So I'm going to leave that. I don't want to go, you know, there's a ton of stuff I can talk through. I'll restrict it to this one thing for now. I will cover this with more structure fairly soon. And hopefully we'll ramble a little bit less. But at least I think with this, you should get an idea of where I'm coming from. And the hopefully, sensible to some degree logic behind what I'm thinking here. But anyway.  that's it so thank you for watching I will definitely try and make sure to release something else very soon but for now I'll leave it there thank you very much watching I will see you in the next one bye You know,\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can count the number of words from our transcribed video:"
      ],
      "metadata": {
        "id": "2jhWMXN1fPsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(content.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7P2_Ppvrt9M",
        "outputId": "e7a574d6-ce29-4b08-8c7d-c4912795bae6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4147"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connecting an LLM"
      ],
      "metadata": {
        "id": "SxNEVO9BUsxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're using Mistral AI in this example and we'll be using both their LLM and embed models, you can get [an API key from here](https://console.mistral.ai/api-keys)."
      ],
      "metadata": {
        "id": "3B5n-85JWbkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from mistralai import Mistral\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"MISTRAL_API_KEY\"] = os.getenv(\"MISTRAL_API_KEY\") or \\\n",
        "    getpass(\"Enter your Mistral API key: \")\n",
        "\n",
        "client = Mistral(api_key=os.environ[\"MISTRAL_API_KEY\"])"
      ],
      "metadata": {
        "id": "Q7rTQEmLYCR3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mistralai.models import (\n",
        "    SystemMessage,\n",
        "    UserMessage\n",
        ")\n",
        "\n",
        "response = client.chat.complete(\n",
        "    model=\"mistral-large-latest\",\n",
        "    messages=[\n",
        "        SystemMessage(content=(\n",
        "            \"You are an AI expert providing help to the user \"\n",
        "            \"based on the content of the provided transcribed \"\n",
        "            \"document.\\n\\n---\\n\\nTranscription:\\n\\n\" +\n",
        "            content\n",
        "        )),\n",
        "        UserMessage(content=\"Hi can you summarize this for me?\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "vIKVQeCnb01r"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get our message content like so:"
      ],
      "metadata": {
        "id": "RwSZvInACmuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices[0].message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_R0bp_kP6VR",
        "outputId": "4a2f0fe6-567e-47bb-9237-33086ba09dc4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AssistantMessage(content=\"Sure, here's a summarized version of the transcribed document:\\n\\nThe speaker discusses their evolving thoughts on AI agents and plans to create a structured video and course on this topic. They highlight that their recent absence from YouTube is due to this work and personal events.\\n\\n**Key Points:**\\n\\n1. **React Agent:**\\n   - The React agent is a foundational structure for LM-based agents, allowing for multiple reasoning steps and tool calls.\\n   - Example: Answering a question about the Apple Remote by using search tools and iterative reasoning.\\n\\n2. **Broad Definition of Agents:**\\n   - The speaker argues that the common definition of agents (LM plus tool calls) is limiting.\\n   - They prefer a neurosymbolic architecture, combining neural networks (like LLMs) with symbolic AI (handwritten rules, code).\\n\\n3. **Historical Context of AI:**\\n   - **Symbolic AI:** Traditional approach using rules and ontologies (e.g., syllogistic logic).\\n   - **Neural AI:** Inspired by brain mechanisms, using neural networks and perceptrons.\\n   - **AI Winters:** Periods of reduced interest in AI, particularly neural AI, until breakthroughs like ImageNet and AlexNet.\\n\\n4. **Neurosymbolic Architecture:**\\n   - Combines neural networks (learned representations) with symbolic AI (handwritten code, rules).\\n   - Example: Using embedding models to route queries directly to tools or modify queries for LLM processing.\\n\\n5. **Flexible Agent Definition:**\\n   - Agents should be viewed more flexibly, not just as LLMs calling tools.\\n   - Different tools and paths can be used based on the context and intent of the query.\\n\\nThe speaker plans to release more structured content on this topic soon.\\n\\nIn essence, the speaker advocates for a broader, more flexible definition of AI agents that combines neural and symbolic elements, drawing from historical AI concepts.\", tool_calls=None, prefix=False, role='assistant')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also track our usage:"
      ],
      "metadata": {
        "id": "VSuB_nf2QDiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.usage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPO_BvjfQGO3",
        "outputId": "7f89a1a2-ead0-4e79-9405-c2d6809e4d4b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UsageInfo(prompt_tokens=5429, completion_tokens=435, total_tokens=5864)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding Chat History"
      ],
      "metadata": {
        "id": "vUmAVPhUCs88"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make our video chat conversational we need to maintain chat history — to do that we'll write an `Agent` class that we can initialize and interact with, it will maintain our messages within this class."
      ],
      "metadata": {
        "id": "jBWZxTZ7Cvs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mistralai.models import AssistantMessage, UsageInfo\n",
        "\n",
        "class Agent:\n",
        "    messages: list[AssistantMessage | SystemMessage | UserMessage]\n",
        "    usage: list[UsageInfo]\n",
        "\n",
        "    def __init__(self):\n",
        "        self.messages = [\n",
        "            SystemMessage(content=(\n",
        "                \"You are an AI expert providing help to the user \"\n",
        "                \"based on the content of the provided transcribed \"\n",
        "                \"document.\\n\\n---\\n\\nTranscription:\\n\\n\" +\n",
        "                content\n",
        "            ))\n",
        "        ]\n",
        "        self.usage = []\n",
        "\n",
        "    def chat(self, content: str) -> AssistantMessage:\n",
        "        # append user message to self.messages\n",
        "        self.messages.append(UserMessage(content=content))\n",
        "        # generate response\n",
        "        response = client.chat.complete(\n",
        "            model=\"mistral-large-latest\",\n",
        "            messages=self.messages\n",
        "        )\n",
        "        # append assistant message to self.messages\n",
        "        self.messages.append(response.choices[0].message)\n",
        "        # append usage (we can use this later)\n",
        "        self.usage.append(response.usage)\n",
        "        return response.choices[0].message"
      ],
      "metadata": {
        "id": "qyC6UWSuoi0A"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can chat with our conversational history agent:"
      ],
      "metadata": {
        "id": "zc-iJPlV3Hl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "# initialize\n",
        "agent = Agent()\n",
        "\n",
        "res = agent.chat(\n",
        "    content=\"can you summarize the meaning of 'symbolic' in this article?\"\n",
        ")\n",
        "# print output in markdown\n",
        "display(Markdown(res.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "QJMRF_U13Nuy",
        "outputId": "60ae48f9-f7f2-41ae-bc17-cde6bd7648cb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "In the context of the article, \"symbolic\" refers to a traditional approach to artificial intelligence that involves using handwritten rules, ontologies, and logical functions to build AI systems. This approach is often associated with the early days of AI research, where the goal was to achieve true AGI (Artificial General Intelligence) through structured, logical frameworks.\n\nKey points about the symbolic approach mentioned in the article include:\n\n1. **Historical Context**: The symbolic approach was prominent in the 1940s, 1950s, and 1960s, and possibly into the 1970s. It is sometimes referred to as \"good, old-fashioned AI\" (GOFAI).\n\n2. **Logical Frameworks**: This approach involves creating logical methodologies, such as syllogistic logic, where conclusions are drawn from major and minor premises. For example, if all dogs have four legs (major premise) and Japs is a dog (minor premise), then Japs has four legs (conclusion).\n\n3. **Handwritten Rules**: The symbolic approach relies on written rules and philosophical grammars to construct deeper, AGI-type systems.\n\n4. **Contrast with Neural AI**: Unlike neural or connectionist AI, which is inspired by the mechanisms of the brain and involves neural networks and perceptrons, the symbolic approach focuses on explicit, logical representations.\n\n5. **Neurosymbolic Architecture**: The article discusses a neurosymbolic architecture, which combines neural networks (the neural part) with runnable code or handwritten rules (the symbolic part). This hybrid approach is seen as more flexible and powerful than using neural networks alone.\n\nIn summary, \"symbolic\" in this article refers to the use of explicit, logical rules and frameworks to build AI systems, contrasting with the neural approach that relies on learning and neural networks."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's ask another question which requires context of the previous interactions:"
      ],
      "metadata": {
        "id": "tB9GA5545ICd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = agent.chat(\n",
        "    content=\"can you give me that but in short bullet-points?\"\n",
        ")\n",
        "# print output in markdown\n",
        "display(Markdown(res.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "ErB0t7a_5L49",
        "outputId": "80029892-e96e-4417-cab6-5929e6e41b6e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Sure, here are the key points about \"symbolic\" in the article in short bullet-points:\n\n- **Historical Context**: Prominent in the 1940s-1970s, often called \"good, old-fashioned AI\" (GOFAI).\n- **Logical Frameworks**: Uses structured, logical methodologies like syllogistic logic.\n- **Handwritten Rules**: Relies on explicit, handwritten rules and ontologies.\n- **Contrast with Neural AI**: Unlike neural AI, which is inspired by brain mechanisms and uses neural networks.\n- **Neurosymbolic Architecture**: Combines neural networks with runnable code or handwritten rules for a more flexible AI system.\n\nThese points summarize the meaning of \"symbolic\" in the context of the article."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Async and Streaming"
      ],
      "metadata": {
        "id": "ZkT9G5tCLCZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When developing AI apps that rely heavily on external APIs we tend to write async code to make our applications more scalable. With async code the time that our code would be spent waiting for API responses can instead be spent performing other tasks.\n",
        "\n",
        "We will rewrite our `Agent` class to work fully asynchronously, and we'll also add streaming — which can provide an improved user experience as we can show the user the tokens as soon as they're generated."
      ],
      "metadata": {
        "id": "ObxCjinJTOfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "\n",
        "class Agent:\n",
        "    messages: list[AssistantMessage | SystemMessage | UserMessage]\n",
        "    usage: list[UsageInfo]\n",
        "    queue: asyncio.Queue | None = None\n",
        "\n",
        "    def __init__(self):\n",
        "        self.messages = [\n",
        "            SystemMessage(content=(\n",
        "                \"You are an AI expert providing help to the user \"\n",
        "                \"based on the content of the provided transcribed \"\n",
        "                \"document.\\n\\n---\\n\\nTranscription:\\n\\n\" +\n",
        "                content\n",
        "            ))\n",
        "        ]\n",
        "        self.usage = []\n",
        "\n",
        "    async def chat(self, content: str) -> AssistantMessage:\n",
        "        # append user message to self.messages\n",
        "        self.messages.append(UserMessage(content=content))\n",
        "        # generate response asynchronously\n",
        "        response = await client.chat.stream_async(\n",
        "            model=\"mistral-large-latest\",\n",
        "            messages=self.messages\n",
        "        )\n",
        "        # full response object to be built\n",
        "        all_tokens = []\n",
        "        all_usage = []\n",
        "        # iterate through the token generator and add to queue\n",
        "        async for chunk in response:\n",
        "            if (token := chunk.data.choices[0].delta.content) is not None:\n",
        "                print(token, end=\"\", flush=True)\n",
        "                all_tokens.append(token)\n",
        "        # append assistant message to self.messages\n",
        "        self.messages.append(AssistantMessage(content=\"\".join(all_tokens)))\n",
        "        # append usage (we can use this later)\n",
        "        self.usage.append(chunk.data.usage)\n",
        "        return self.messages[-1]"
      ],
      "metadata": {
        "id": "DKBiCzqnS75z"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = Agent()\n",
        "\n",
        "res = await agent.chat(\n",
        "    content=\"can you summarize the meaning of 'symbolic' in this article?\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pm4TJWNI8RhY",
        "outputId": "83703de8-231c-4062-b92a-05e2e3ea1c52"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the context of the article, \"symbolic\" refers to the traditional approach to artificial intelligence that relies on handwritten rules, ontologies, and logical functions to build AI systems. This approach is often associated with the early days of AI research, where the goal was to achieve true Artificial General Intelligence (AGI) through structured, logical frameworks.\n",
            "\n",
            "Key points about the symbolic approach mentioned in the article:\n",
            "\n",
            "1. **Historical Context**: The symbolic approach was prominent in the 1940s, 1950s, and 1960s, and possibly into the 1970s. It is sometimes referred to as \"good old-fashioned AI\" (GOFAI).\n",
            "\n",
            "2. **Logical Frameworks**: This approach involves using logical frameworks like syllogistic logic, which includes major premises, minor premises, and conclusions. For example, if all dogs have four legs and Japs is a dog, then Japs has four legs.\n",
            "\n",
            "3. **Handwritten Rules**: Symbolic AI relies on manually crafted rules and ontologies to create intelligent systems. This contrasts with the neural or connectionist approach, which learns patterns from data.\n",
            "\n",
            "4. **Neuro-Symbolic Architecture**: The article discusses a neuro-symbolic architecture, which combines neural networks (the neural part) with handwritten code or rules (the symbolic part). This hybrid approach leverages the strengths of both traditional AI and modern neural networks.\n",
            "\n",
            "In summary, \"symbolic\" in this article refers to the use of predefined rules and logical structures to create AI systems, contrasting with the data-driven, learning-based approach of neural networks."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can continue our conversation:"
      ],
      "metadata": {
        "id": "AA5w6SF6Dle8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = await agent.chat(\n",
        "    content=\"tell me in more detail what was said on point (1)\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKGTZCiwDoYm",
        "outputId": "c3594e2d-dddb-4f0b-8243-02f10527e8a9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly! Here's a more detailed breakdown of point (1), the historical context of the symbolic approach to AI as discussed in the article:\n",
            "\n",
            "### Historical Context of Symbolic AI\n",
            "\n",
            "**Early Days of AI Research:**\n",
            "- The symbolic approach to AI has its roots in the early days of AI research, roughly from the 1940s to the 1970s.\n",
            "- During this period, AI researchers believed that true Artificial General Intelligence (AGI) could be achieved through the creation of explicit rules, ontologies, and logical functions.\n",
            "\n",
            "**Philosophical Foundations:**\n",
            "- The philosophical underpinnings of symbolic AI can be traced back to logical frameworks like syllogistic logic, which was developed by Aristotle.\n",
            "- Syllogistic logic involves using major premises, minor premises, and conclusions to form logical deductions. For example:\n",
            "  - Major Premise: All dogs have four legs.\n",
            "  - Minor Premise: Japs is a dog.\n",
            "  - Conclusion: Japs has four legs.\n",
            "\n",
            "**Good Old-Fashioned AI (GOFAI):**\n",
            "- The symbolic approach is sometimes referred to as \"good old-fashioned AI\" (GOFAI). This term highlights the traditional, rule-based nature of this approach compared to more modern, data-driven methods.\n",
            "- GOFAI focuses on creating intelligent systems through the manual crafting of rules and logical structures, rather than relying on learning from data.\n",
            "\n",
            "**Contrast with Neural/Connectionist AI:**\n",
            "- The symbolic approach contrasts with the neural or connectionist approach, which emerged later and focuses on building AI systems loosely based on the mechanisms of the human brain.\n",
            "- The connectionist approach uses neural networks and perceptrons, which learn patterns from data rather than relying on predefined rules.\n",
            "\n",
            "**AI Winters:**\n",
            "- The article mentions that there were periods of reduced interest in AI, particularly in neural or connectionist AI, known as \"AI winters.\" During these periods, the symbolic approach may have continued to receive attention, but overall interest in AI waned.\n",
            "\n",
            "**Resurgence of Neural AI:**\n",
            "- The resurgence of interest in neural AI occurred around 2011-2012 with the success of models like AlexNet on the ImageNet dataset. This renewed interest led to the widespread adoption of neural networks and the development of modern AI technologies like transformers and large language models (LLMs).\n",
            "\n",
            "In summary, the symbolic approach to AI, prominent in the mid-20th century, relied on handwritten rules and logical frameworks to create intelligent systems. This method contrasts with the neural or connectionist approach, which learns from data and has seen a resurgence in recent decades."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = await agent.chat(\n",
        "    content=\"and what does that have to do with AI agents?\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFo0FbCjDzLm",
        "outputId": "6746ac58-13f6-4037-f9cf-59768811146d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the context of the article, the historical and philosophical foundations of symbolic AI are relevant to the discussion on AI agents in several ways:\n",
            "\n",
            "### Broadening the Definition of AI Agents\n",
            "\n",
            "1. **Neuro-Symbolic Architecture**:\n",
            "   - The article introduces the concept of a neuro-symbolic architecture, which combines neural networks (the neural part) with handwritten code or rules (the symbolic part). This hybrid approach is presented as a more comprehensive definition of AI agents.\n",
            "   - By incorporating both neural and symbolic elements, AI agents can leverage the strengths of traditional rule-based systems and modern data-driven learning methods.\n",
            "\n",
            "2. **Flexibility and Versatility**:\n",
            "   - The author argues that limiting the definition of AI agents to just Large Language Models (LLMs) that can call tools is too restrictive. Instead, AI agents should be seen as systems that can incorporate a variety of neural network-based models and symbolic components.\n",
            "   - This broader definition allows for more flexible and versatile agent designs, capable of handling a wider range of tasks and scenarios.\n",
            "\n",
            "### Practical Implications for AI Agent Design\n",
            "\n",
            "3. **Embedding Models and Semantic Routers**:\n",
            "   - The article discusses the use of embedding models, which are neural network-based, to route user queries to appropriate tools or pipelines. This is an example of how neural and symbolic components can work together in an AI agent.\n",
            "   - For instance, an embedding model can identify the intent behind a user query and direct it to a specific tool or pipeline, bypassing the need for an LLM to make this decision. This makes the system more efficient and controllable.\n",
            "\n",
            "4. **Tool Selection and Decision-Making**:\n",
            "   - The author explains that AI agents can use neural networks to make initial decisions and then employ symbolic rules or tools to execute follow-on actions. This approach allows for more nuanced and context-aware decision-making.\n",
            "   - For example, an LLM might decide which tool to use based on the user's query, and then symbolic rules or code can handle the specific actions required by that tool.\n",
            "\n",
            "### Philosophical and Historical Grounding\n",
            "\n",
            "5. **Anchor in AI History**:\n",
            "   - The definition of AI agents as neuro-symbolic systems is anchored in the history and philosophy of AI, providing a solid foundation that spans nearly a century of research.\n",
            "   - This historical context lends credibility and depth to the idea that AI agents should be more than just LLMs with tool-calling capabilities.\n",
            "\n",
            "6. **Addressing Limitations of Purely Neural or Symbolic Approaches**:\n",
            "   - The article acknowledges the limitations of purely neural or purely symbolic approaches. Neural networks alone may lack the precision and control of symbolic rules, while symbolic systems alone may struggle with the complexity and variability of real-world data.\n",
            "   - By combining these approaches, AI agents can overcome these limitations and achieve more robust and effective performance.\n",
            "\n",
            "In summary, the historical and philosophical foundations of symbolic AI are integral to the article's argument for a broader, more flexible definition of AI agents. This neuro-symbolic approach allows for the creation of agents that are versatile, efficient, and capable of handling a wide range of tasks by leveraging both rule-based and data-driven methods."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizing Token Cost"
      ],
      "metadata": {
        "id": "sL-RRGxTC2_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Throwing the full article into each interaction will give us maximal accuracy but is also _expensive_.\n",
        "\n",
        "We can see this by checking our token usage and calculating our costs. To check our usage we simply access our agent's `usage` attribute:"
      ],
      "metadata": {
        "id": "jlC3a0l-C7GB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent.usage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akf2T_cGEDEj",
        "outputId": "2d68d0b2-010a-4cb6-b729-84742faac0d0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[UsageInfo(prompt_tokens=5435, completion_tokens=369, total_tokens=5804),\n",
              " UsageInfo(prompt_tokens=5820, completion_tokens=613, total_tokens=6433),\n",
              " UsageInfo(prompt_tokens=6447, completion_tokens=729, total_tokens=7176)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To estimate our costs for running our agent, we can take the latest pricing for Mistral's large model for `prompt_tokens` (input) and `completion_tokens` (output) from their [pricing page](https://mistral.ai/en/products/la-plateforme#pricing).\n",
        "\n",
        "As of 08 March 2025 those prices are:\n",
        "\n",
        "| Model | API name | Input (/M tokens) | Output (/M tokens) |\n",
        "| ----- | -------- | ----------------- | ------------------ |\n",
        "| Mistral Large 24.11 | mistral-large-latest | \\$2 | \\$6 |\n",
        "\n",
        "We can define a cost calculator like so:"
      ],
      "metadata": {
        "id": "BgWXWmyTEKF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost(usage: UsageInfo) -> float:\n",
        "    input_cost = usage.prompt_tokens * 2e-6\n",
        "    output_cost = usage.completion_tokens * 2e-6\n",
        "    return round(input_cost + output_cost, 5)"
      ],
      "metadata": {
        "id": "5P3zFl9iEX-f"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save these values for later reference\n",
        "original_cost = []\n",
        "\n",
        "for usage in agent.usage:\n",
        "    usage_cost = cost(usage=usage)\n",
        "    original_cost.append(usage_cost)\n",
        "    print(f\"${usage_cost}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAl-rNANGg7O",
        "outputId": "1bb3c71d-330b-419c-91d1-45941fa9a098"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$0.01161\n",
            "$0.01287\n",
            "$0.01435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These seem like small numbers but they will quickly add up as we continue throwing the full transcription into our LLM with every new interaction.\n",
        "\n",
        "To optimize our token cost we can pull in _only_ the most relevant chunks of information, making use of semantic similarity. To do this we will:\n",
        "\n",
        "1. Break our transcribed document into smaller chunks.\n",
        "2. Embed those chunks into vector embeddings.\n",
        "3. Store those vector embeddings in a numpy array.\n",
        "4. When querying, our LLM (now agent) will transform our question into a small query.\n",
        "5. We embed that query into a vector embedding.\n",
        "6. Compare the semantic similarity between our query vector and our chunk vectors to find the most similar chunks.\n",
        "7. Return those chunks to our LLM ready for a final response.\n",
        "\n",
        "Let's start by chunking our document, we use the _async_ Aurelio chunking endpoint for this:"
      ],
      "metadata": {
        "id": "Lrv04LllHXZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from aurelio_sdk import AsyncAurelioClient\n",
        "\n",
        "# we reinitialize the client for async\n",
        "aurelio_client = AsyncAurelioClient()"
      ],
      "metadata": {
        "id": "D5kmU3LHC6rx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call the chunk endpoint on our document:"
      ],
      "metadata": {
        "id": "3p_09ISXMB_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from aurelio_sdk import ChunkingOptions\n",
        "\n",
        "# we use a semantic chunker with a max chunk length of 400 tokens\n",
        "chunking_options = ChunkingOptions(\n",
        "    chunker_type=\"semantic\",\n",
        "    max_chunk_length=500,\n",
        "    window_size=3\n",
        ")\n",
        "\n",
        "chunks = await aurelio_client.chunk(\n",
        "    content=content,\n",
        "    processing_options=chunking_options\n",
        ")"
      ],
      "metadata": {
        "id": "Y6MXwoY6MBYs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the chunks like so:"
      ],
      "metadata": {
        "id": "gk3N7dwTNX5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunks.document.chunks[5:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x80kGzKMX__",
        "outputId": "a6b389ac-fec8-45d5-b8b7-75250d67660d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ResponseChunk(id='chunk_7427b07a-7203-4778-8be9-2698176507f9', content=\"I know that Apple remote controls the front row program.  but what other device controls the front row program. So it says, okay, based on this, my next reasoning step is I need to search front row and find other devices that control it. So then it does this search for front row. It could also probably do something, if we're thinking in rag terms here, it could be like device to control front row. And probably more today LM would do that. But that's fine. this is just an example. So it goes back to the search tool again and it says query.\", chunk_index=6, num_tokens=121, metadata={}),\n",
              " ResponseChunk(id='chunk_8c3acf5f-33b8-419c-94e5-4dbf706b1496', content=\"Front row. And this isn't  I've shortened this for the sake of brevity. I think in the actual example, or at least from the paper, the actual example returns a lot more information. But this is the part of it that is important.\", chunk_index=7, num_tokens=54, metadata={}),\n",
              " ResponseChunk(id='chunk_43a3a3b4-f0bb-470e-a724-e710ae6aa1c4', content=\"The front row is controlled by an Apple remote or keyboard function keys. Okay, so now we know that. That gets fed back into the LM. So the LM now knows everything that we've covered here, knows the original query. And now it's like, okay, well, I have all the information that I need to answer the original query which is site to a map or remote what other device can control front row  So the next step is the LM is like, oh, okay, I have everything.\", chunk_index=8, num_tokens=104, metadata={}),\n",
              " ResponseChunk(id='chunk_bb8d62c8-db92-41c5-a9dc-3a154997d0d2', content=\"I can now provide the answer of keyboard function keys to the user. Okay. And so it doesn't use a search tool. Now it instead uses the answer tool, which has this query, this, sorry, parameter out. And the answer or the output for that is keyboard function keys, which then gets provided back to the user. that.\", chunk_index=9, num_tokens=70, metadata={}),\n",
              " ResponseChunk(id='chunk_6db68cd3-7cee-4fb7-8519-68d5b2216d4c', content=\"Okay. So this is the React agent and this sort of structure of like reasoning, building  a like a query for a tool, getting a response, and then potentially going through another iteration of reasoning and action and another and then eventually providing an answer. That is really the sort of commonly accept a definition of what an agent is. That's what most people are using at the moment. And I think that is great, but I think it's very limiting. because I just wouldn't, in production, I would never just put something like this, whether it's React or Open AI tools or whatever else. I wouldn't just put that. In my opinion, an agent is much broader than just what this is. And also in general, broader literature, an agent is not just this either. So I went back and I just went through a few papers trying to figure out, okay, what is the actual good definition of an agent that kind of makes sense in the way that I also understand the agents, the way that I've been building like agentic, more workflows to be honest, right? But to me, workflow or agent is kind of  Same thing. It's agentic workflow, i.e. agent. So, anyway, I went back and the paper that I think had the nicest definition that tied back to really like original, like, AI, well, philosophy, like the original AI philosophy or the original AI research, maybe not original, but pretty close to original, and I don't think maybe original, was this, right? So it was a miracle paper, right, which is another.\", chunk_index=10, num_tokens=329, metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to embed each chunk. For that we will use Mistral's embedding model."
      ],
      "metadata": {
        "id": "SpMsluS-N1io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_response = await client.embeddings.create_async(\n",
        "    model=\"mistral-embed\",\n",
        "    inputs=[x.content for x in chunks.document.chunks]\n",
        ")"
      ],
      "metadata": {
        "id": "J0g6x1SuNK4X"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This returns a list of `EmbeddingResponseData` objects inside the `.data` attribute:"
      ],
      "metadata": {
        "id": "GtW8CP5-PvFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings_response.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uar1GBhrO8J9",
        "outputId": "9475eb8a-2bbc-4469-c97b-9f6348d7656a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each of those `EmbeddingResponseData` objects contains a single vector embedding inside the `.embedding` attribute. The dimensionality of the embedding model is `1024` which we can see below:"
      ],
      "metadata": {
        "id": "ofEcEaqSP3Ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings_response.data[0].embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiHpHU-9P2zj",
        "outputId": "b44672d7-51bf-44ab-9ac1-86b03ec855c7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we must add all of these vectors to a single numpy array:"
      ],
      "metadata": {
        "id": "aP1B_-wNQH2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "video_emb = np.asarray([x.embedding for x in embeddings_response.data])\n",
        "# check the dimensionality of our video chunks array\n",
        "video_emb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NitxTBYxQO5u",
        "outputId": "b6723012-96f9-4d96-c4a4-926b6ee2070f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this we can see we have 35 1024-dimensional vector embeddings that represent our full transcribed document. Now to plug this back into our agent we will create a `query` tool that will allow our LLM to provide a natural language query and return the most relevant chunks based on that query.\n",
        "\n",
        "Let's start by writing this tool step-by-step. First, we create a _query vector_:"
      ],
      "metadata": {
        "id": "0io3Hze3QiC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is the relationship between AI agents and GOFAI?\"\n",
        "\n",
        "embeddings_response = await client.embeddings.create_async(\n",
        "    model=\"mistral-embed\",\n",
        "    inputs=[query]\n",
        ")\n",
        "xq = np.asarray(embeddings_response.data[0].embedding)\n",
        "xq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtpcuqWXSOhJ",
        "outputId": "00e21110-c580-47ef-a628-0af163213c56"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1024,)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now calculate the dot product similarity between our query vector `xq` and precomputed document chunk vectors."
      ],
      "metadata": {
        "id": "NPV_y0q7SoaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sim_arr = np.dot(xq, video_emb.T)\n",
        "sim_arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUcs6hOrSvrf",
        "outputId": "bb989959-b0ed-40a0-a8aa-95f5ad1ff91e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.6828565 , 0.75058198, 0.69919688, 0.67968833, 0.61341964,\n",
              "       0.60867901, 0.62188296, 0.60628245, 0.60307181, 0.74770941,\n",
              "       0.76357249, 0.61461822, 0.75837007, 0.75699921, 0.64369794,\n",
              "       0.71479521, 0.65117063, 0.68480309, 0.71202544, 0.69951878,\n",
              "       0.68277037, 0.68066402, 0.74412483, 0.64809726, 0.66284248,\n",
              "       0.64783145, 0.62315144, 0.62955026, 0.7012869 , 0.70282584,\n",
              "       0.67379309, 0.68034123, 0.70010112, 0.61695457, 0.57207087])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we return the indexes for the `top_k` most similar (highest scoring) chunks:"
      ],
      "metadata": {
        "id": "NCUmqigGTY5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = 3  # we'll set top_k to 3, returning the 3 most similar chunks\n",
        "\n",
        "most_similar_idx = np.argsort(sim_arr)[-top_k:][::-1]\n",
        "most_similar_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo73Gxy9T2rq",
        "outputId": "e937cd9d-c621-493d-fc03-39e5b3f519dd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before pulling the content of each chunk, we convert our list of chunks into an array of chunks — these will speed up our chunk content retrieval later."
      ],
      "metadata": {
        "id": "BFQ8dpm8UI3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunks_content = np.asarray([x.content for x in chunks.document.chunks])\n",
        "chunks_content.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lhJaZT9UPgR",
        "outputId": "4c9653dc-14d7-43e9-99ab-c2afd5851127"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35,)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now retrieve the chunks content:"
      ],
      "metadata": {
        "id": "4gPo6gROUvrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunks_content[most_similar_idx]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_i3SOsRUyMk",
        "outputId": "69f05c3b-4c60-49bd-967b-867df96962db"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\". .  basically agent, LM agent. I think this came just before the React agent paper. It's very similar, I would say, has a bit less structured in the React agent. But, yeah, it's super relevant. And the way that they described their system was that it was a neurosymbolic architecture. I really like this definition because a, so neurosymbolic architecture, It's two things, right? You have the neural part, you have the symbolic part. And I actually have another kind of starting  on this article but it's uh yeah there's this mostly notes at the moment so the neural part of this in fact let's start with the symbolic part the symbolic part is the more traditional AI right so the you know I think this is back in the 40s 50s 60s mostly and then maybe so actually 70s as well this was actually maybe not 70s this was this was a the sort of traditional approach to AI. And the idea,  or the symbolists that were just like full on symbolists felt that true AGI would be achieved through written rules, ontologies and these other logical functions to basically a load of handwritten stuff, like smart, like philosophical grammars. An example of this is the, I think it's syllogistic logic from Aristotle. and the, so basically, an example of this would be a, I think it's got,  you have this major premise then you have a minor premise and i haven't done this for a long time so forgive me if i'm not super accurate um but you have a major premise minor premise and conclusion based on that so the idea is like if you say something like um all all dogs have four legs which is maybe not actually true but let's just assume that you like all dogs have four legs by nature.\",\n",
              "       \"Okay, so this is a logical framework developed by Arisothel. And the symbolic AI people would, you know, do things like these, these sort of exercises where they're going through all this and trying to build up some sort of logical methodology to allow you to kind of construct some deeper, like aGI type system where it can just kind of figure everything out. Now, that was like one side of AI back then. And this is like the traditional AI, it's also called like good,  old fashioned AI.\",\n",
              "       \"I don't remember who or when that was turned, but gofi. I don't know if they actually call it gofi, but that's how it's written. And yeah, I mean, that was one camp. The other camp were the connectionists. So this is what we, we call them back then. Now it's kind of the neural AI type thing. So connectionism was in, so kind of emerged back in 9. there was this basically a paper that described a neural circuit. But really, the where neural or connectionist AI really started with is with this guy, Rosenblatt, who introduced this idea of a perceptron. And it's actually the perceptron is in an adapted version of the perceptron that he described is what we use in neural networks today.\"],\n",
              "      dtype='<U1670')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see here that we've returned the chunks of our article _most_ relevant to our query. Now we wrap all of this up into a single function, ie our _tool_:"
      ],
      "metadata": {
        "id": "JOVPIPzVVENM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def search(query: str) -> str:\n",
        "    \"\"\"Use this tool to search for relevant chunks of information\n",
        "    from the provided video. Provide as much context as possible\n",
        "    to the `query` parameter, ensuring to write your search\n",
        "    query in natural language. If you must answer multiple\n",
        "    questions you should use this tool to only answer one at a\n",
        "    time. Do not include multiple questions in the `query`.\"\"\"\n",
        "    # embed our query to create a 'query vector'\n",
        "    embeddings_response = await client.embeddings.create_async(\n",
        "        model=\"mistral-embed\",\n",
        "        inputs=[query]\n",
        "    )\n",
        "    xq = np.asarray(embeddings_response.data[0].embedding)\n",
        "    # perform the similarity search\n",
        "    sim_arr = np.dot(xq, video_emb.T)\n",
        "    # get the top_k most similar chunks\n",
        "    most_similar_idx = np.argsort(sim_arr)[-top_k:][::-1]\n",
        "    # return our most relevant chunks\n",
        "    return \"\\n---\\n\".join(chunks_content[most_similar_idx].tolist())"
      ],
      "metadata": {
        "id": "g__6FpSuO-QO"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test quickly:"
      ],
      "metadata": {
        "id": "dE9SB1NzV_D1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(await search(query=query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsJw3Z8tV-b7",
        "outputId": "b556ee25-e6d2-4882-842d-21a53fe7a4f1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ". .  basically agent, LM agent. I think this came just before the React agent paper. It's very similar, I would say, has a bit less structured in the React agent. But, yeah, it's super relevant. And the way that they described their system was that it was a neurosymbolic architecture. I really like this definition because a, so neurosymbolic architecture, It's two things, right? You have the neural part, you have the symbolic part. And I actually have another kind of starting  on this article but it's uh yeah there's this mostly notes at the moment so the neural part of this in fact let's start with the symbolic part the symbolic part is the more traditional AI right so the you know I think this is back in the 40s 50s 60s mostly and then maybe so actually 70s as well this was actually maybe not 70s this was this was a the sort of traditional approach to AI. And the idea,  or the symbolists that were just like full on symbolists felt that true AGI would be achieved through written rules, ontologies and these other logical functions to basically a load of handwritten stuff, like smart, like philosophical grammars. An example of this is the, I think it's syllogistic logic from Aristotle. and the, so basically, an example of this would be a, I think it's got,  you have this major premise then you have a minor premise and i haven't done this for a long time so forgive me if i'm not super accurate um but you have a major premise minor premise and conclusion based on that so the idea is like if you say something like um all all dogs have four legs which is maybe not actually true but let's just assume that you like all dogs have four legs by nature.\n",
            "---\n",
            "Okay, so this is a logical framework developed by Arisothel. And the symbolic AI people would, you know, do things like these, these sort of exercises where they're going through all this and trying to build up some sort of logical methodology to allow you to kind of construct some deeper, like aGI type system where it can just kind of figure everything out. Now, that was like one side of AI back then. And this is like the traditional AI, it's also called like good,  old fashioned AI.\n",
            "---\n",
            "I don't remember who or when that was turned, but gofi. I don't know if they actually call it gofi, but that's how it's written. And yeah, I mean, that was one camp. The other camp were the connectionists. So this is what we, we call them back then. Now it's kind of the neural AI type thing. So connectionism was in, so kind of emerged back in 9. there was this basically a paper that described a neural circuit. But really, the where neural or connectionist AI really started with is with this guy, Rosenblatt, who introduced this idea of a perceptron. And it's actually the perceptron is in an adapted version of the perceptron that he described is what we use in neural networks today.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to redefine our `Agent` and plug our new tool into it. To do that we need to format our tool so that the Mistral API can read it:"
      ],
      "metadata": {
        "id": "WJCKrNc3WUH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "\n",
        "inspect.getdoc(search)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "wo1la0X9X96g",
        "outputId": "b3949980-4d1b-4412-ace2-872fe152f375"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Use this tool to search for relevant chunks of information\\nfrom the provided video. Provide as much context as possible\\nto the `query` parameter, ensuring to write your search\\nquery in natural language. If you must answer multiple \\nquestions you should use this tool to only answer one at a\\ntime. Do not include multiple questions in the `query`.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "func_schema = {\n",
        "    \"name\": search.__name__,\n",
        "    \"description\": inspect.getdoc(search),\n",
        "    \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
        "}\n",
        "func_schema"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_4RAxhmXHVQ",
        "outputId": "d4cc9242-410e-4c4e-e82b-9800b564af87"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'search',\n",
              " 'description': 'Use this tool to search for relevant chunks of information\\nfrom the provided video. Provide as much context as possible\\nto the `query` parameter, ensuring to write your search\\nquery in natural language. If you must answer multiple \\nquestions you should use this tool to only answer one at a\\ntime. Do not include multiple questions in the `query`.',\n",
              " 'parameters': {'type': 'object', 'properties': {}, 'required': []}}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtype_map = {\n",
        "    int: \"number\",\n",
        "    float: \"number\",\n",
        "    str: \"string\",\n",
        "    bool: \"boolean\",\n",
        "    None: \"null\",\n",
        "    list: \"array\",\n",
        "}"
      ],
      "metadata": {
        "id": "Fg5WaBBBa2hq"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signature = inspect.signature(search)\n",
        "for name, dtype in signature.parameters.items():\n",
        "    # add param to properties\n",
        "    func_schema[\"parameters\"][\"properties\"][name] = {\n",
        "        \"type\": dtype_map.get(dtype.annotation, \"object\")\n",
        "    }\n",
        "    # and required (assuming all are required)\n",
        "    func_schema[\"parameters\"][\"required\"].append(name)"
      ],
      "metadata": {
        "id": "PANBF-fZY5kf"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have our fully defined function schema:"
      ],
      "metadata": {
        "id": "LDbaaWLrcLP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "func_schema"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8twTQVHYWC6",
        "outputId": "30f09c3c-3c09-423c-b56f-de830ca548fe"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'search',\n",
              " 'description': 'Use this tool to search for relevant chunks of information\\nfrom the provided video. Provide as much context as possible\\nto the `query` parameter, ensuring to write your search\\nquery in natural language. If you must answer multiple \\nquestions you should use this tool to only answer one at a\\ntime. Do not include multiple questions in the `query`.',\n",
              " 'parameters': {'type': 'object',\n",
              "  'properties': {'query': {'type': 'string'}},\n",
              "  'required': ['query']}}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We transform this into a `mistralai` `Function` object:"
      ],
      "metadata": {
        "id": "g24ZBGWCcdmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mistralai.models.function import Function\n",
        "\n",
        "tool_signatures = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": Function(\n",
        "            name=func_schema[\"name\"],\n",
        "            description=func_schema[\"description\"],\n",
        "            parameters=func_schema[\"parameters\"]\n",
        "        )\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "iN7FgO4XcixE"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can add our new `tool_signatures` list to our completion call within our `Agent`."
      ],
      "metadata": {
        "id": "yg8KM0G6dIcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from typing import Callable\n",
        "\n",
        "\n",
        "class Agent:\n",
        "    messages: list[AssistantMessage | SystemMessage | UserMessage]\n",
        "    usage: list[UsageInfo]\n",
        "    tool_signatures: list[Function]\n",
        "    queue: asyncio.Queue | None = None\n",
        "\n",
        "    def __init__(self, tool_signatures: list[Function]):\n",
        "        self.messages = [\n",
        "            SystemMessage(content=(\n",
        "                \"You are an AI expert providing help to the user \"\n",
        "                \"based on the content of the provided transcribed \"\n",
        "                \"document.\"\n",
        "            ))\n",
        "        ]\n",
        "        self.usage = []\n",
        "        self.tool_signatures = tool_signatures\n",
        "\n",
        "    async def chat(self, content: str) -> AssistantMessage:\n",
        "        # append user message to self.messages\n",
        "        self.messages.append(UserMessage(content=content))\n",
        "        # generate response asynchronously\n",
        "        response = await client.chat.stream_async(\n",
        "            model=\"mistral-large-latest\",\n",
        "            messages=self.messages,\n",
        "            tools=self.tool_signatures,\n",
        "            tool_choice=\"auto\"\n",
        "        )\n",
        "        # full response object to be built\n",
        "        all_tokens = []\n",
        "        all_usage = []\n",
        "        # iterate through the token generator and add to queue\n",
        "        async for chunk in response:\n",
        "            if isinstance((tool_call := chunk.data.choices[0].delta.tool_calls), list):\n",
        "                print(tool_call)\n",
        "            elif (token := chunk.data.choices[0].delta.content) is not None:\n",
        "                print(token, end=\"\", flush=True)\n",
        "                all_tokens.append(token)\n",
        "        # append assistant message to self.messages\n",
        "        #self.messages.append(AssistantMessage(content=\"\".join(all_tokens)))\n",
        "        # append usage (we can use this later)\n",
        "        #self.usage.append(chunk.data.usage)\n",
        "        return self.messages[-1], tool_call"
      ],
      "metadata": {
        "id": "-b3LG6tUWFI2"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = Agent(tool_signatures=tool_signatures)\n",
        "\n",
        "res = await agent.chat(\n",
        "    content=\"can you summarize the meaning of 'symbolic' in this article?\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WijMyLnde7m",
        "outputId": "545f36d7-02d7-4a3a-e14b-70f10da2df4f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ToolCall(function=FunctionCall(name='search', arguments='{\"query\": \"Meaning of \\'symbolic\\' in the provided article\"}'), id='sKGMXCUCQ', type=None, index=0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our video agent can now create a tool call but it cannot execute the tool call — for that we need a little more scaffolding to handle the detection of a tool call coming from our LLM and the translation of that into execution of our `search` function.\n",
        "\n",
        "To do that, we will create a tool execution function:"
      ],
      "metadata": {
        "id": "prFazOlqcuHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from mistralai.models import ToolCall, ToolMessage\n",
        "\n",
        "tools = [search]\n",
        "\n",
        "tool_map = {t.__name__: t for t in tools}\n",
        "\n",
        "async def execute_tool(tool_call: ToolCall) -> ToolMessage:\n",
        "    tool_name = tool_call.function.name\n",
        "    tool_params = json.loads(tool_call.function.arguments)\n",
        "    tool_call_id = tool_call.id\n",
        "    out = await tool_map[tool_name](**tool_params)\n",
        "    return ToolMessage(\n",
        "        content=out,\n",
        "        name=tool_name,\n",
        "        tool_call_id=tool_call_id\n",
        "    )"
      ],
      "metadata": {
        "id": "8-UW8uoIdnAv"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's take the `tool_call` from our previous `Agent.chat` call and run it through our `execute_tool` function."
      ],
      "metadata": {
        "id": "Mannii8wlVnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res[1][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xsM-ZcPkouk",
        "outputId": "71e2c9b1-f685-4a11-cfb4-b1a9a0b062da"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ToolCall(function=FunctionCall(name='search', arguments='{\"query\": \"Meaning of \\'symbolic\\' in the provided article\"}'), id='sKGMXCUCQ', type=None, index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tool_message = await execute_tool(tool_call=res[1][0])\n",
        "tool_message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqHSnf_hlfh7",
        "outputId": "f1eb66cd-81ed-4b47-88ab-8d8aed64c88a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ToolMessage(content=\". .  basically agent, LM agent. I think this came just before the React agent paper. It's very similar, I would say, has a bit less structured in the React agent. But, yeah, it's super relevant. And the way that they described their system was that it was a neurosymbolic architecture. I really like this definition because a, so neurosymbolic architecture, It's two things, right? You have the neural part, you have the symbolic part. And I actually have another kind of starting  on this article but it's uh yeah there's this mostly notes at the moment so the neural part of this in fact let's start with the symbolic part the symbolic part is the more traditional AI right so the you know I think this is back in the 40s 50s 60s mostly and then maybe so actually 70s as well this was actually maybe not 70s this was this was a the sort of traditional approach to AI. And the idea,  or the symbolists that were just like full on symbolists felt that true AGI would be achieved through written rules, ontologies and these other logical functions to basically a load of handwritten stuff, like smart, like philosophical grammars. An example of this is the, I think it's syllogistic logic from Aristotle. and the, so basically, an example of this would be a, I think it's got,  you have this major premise then you have a minor premise and i haven't done this for a long time so forgive me if i'm not super accurate um but you have a major premise minor premise and conclusion based on that so the idea is like if you say something like um all all dogs have four legs which is maybe not actually true but let's just assume that you like all dogs have four legs by nature.\\n---\\nWell, kind of. To some degree, they are almost kind of mixed together already with neural networks, because neural networks, the way that they work, they almost learn symbols, like they learn logical representations of different concepts, which is what the symbol,  part is in some symbolic they learn these right but they're just not handwritten okay so you know neural network kind of learns what are what a strawberry is or what a dog is but anyway it's kind of side the point um we can just assume okay maybe maybe neural networks are subs symbolic but for now let's just assume they're purely symbolic that's fine so neural networks make up the neural part of this so basically LLMs, then we have this symbolic part. The symbolic part, as I mentioned before, it's handwritten stuff, right?\\n---\\nSo. . .  like code. So if you write some like some code that can be run by a or triggered by an LLM or some other type of neural network that you have some sort of neural's neuro symbolic architecture. You have a mix of both.\", tool_call_id='sKGMXCUCQ', name='search', role='tool')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is our executed tool output. We'd append this alongside an `AssistantMessage` for the initial LLM-generated tool call to our `Agent.messages` attribute, then feed everything back into our LLM for it to decide what to do next. Hopefully, we'll see our LLM deciding to use the information it gathered to respond to the user."
      ],
      "metadata": {
        "id": "3FTnKnowmW_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent.messages.extend([\n",
        "    AssistantMessage(content=\"\", tool_calls=res[1]),\n",
        "    tool_message\n",
        "])\n",
        "agent.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_HRkSlhloCV",
        "outputId": "bc726857-748c-4d0b-e557-48a57a7a2764"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='You are an AI expert providing help to the user based on the content of the provided transcribed document.', role='system'),\n",
              " UserMessage(content=\"can you summarize the meaning of 'symbolic' in this article?\", role='user'),\n",
              " AssistantMessage(content='', tool_calls=[ToolCall(function=FunctionCall(name='search', arguments='{\"query\": \"Meaning of \\'symbolic\\' in the provided article\"}'), id='sKGMXCUCQ', type=None, index=0)], prefix=False, role='assistant'),\n",
              " ToolMessage(content=\". .  basically agent, LM agent. I think this came just before the React agent paper. It's very similar, I would say, has a bit less structured in the React agent. But, yeah, it's super relevant. And the way that they described their system was that it was a neurosymbolic architecture. I really like this definition because a, so neurosymbolic architecture, It's two things, right? You have the neural part, you have the symbolic part. And I actually have another kind of starting  on this article but it's uh yeah there's this mostly notes at the moment so the neural part of this in fact let's start with the symbolic part the symbolic part is the more traditional AI right so the you know I think this is back in the 40s 50s 60s mostly and then maybe so actually 70s as well this was actually maybe not 70s this was this was a the sort of traditional approach to AI. And the idea,  or the symbolists that were just like full on symbolists felt that true AGI would be achieved through written rules, ontologies and these other logical functions to basically a load of handwritten stuff, like smart, like philosophical grammars. An example of this is the, I think it's syllogistic logic from Aristotle. and the, so basically, an example of this would be a, I think it's got,  you have this major premise then you have a minor premise and i haven't done this for a long time so forgive me if i'm not super accurate um but you have a major premise minor premise and conclusion based on that so the idea is like if you say something like um all all dogs have four legs which is maybe not actually true but let's just assume that you like all dogs have four legs by nature.\\n---\\nWell, kind of. To some degree, they are almost kind of mixed together already with neural networks, because neural networks, the way that they work, they almost learn symbols, like they learn logical representations of different concepts, which is what the symbol,  part is in some symbolic they learn these right but they're just not handwritten okay so you know neural network kind of learns what are what a strawberry is or what a dog is but anyway it's kind of side the point um we can just assume okay maybe maybe neural networks are subs symbolic but for now let's just assume they're purely symbolic that's fine so neural networks make up the neural part of this so basically LLMs, then we have this symbolic part. The symbolic part, as I mentioned before, it's handwritten stuff, right?\\n---\\nSo. . .  like code. So if you write some like some code that can be run by a or triggered by an LLM or some other type of neural network that you have some sort of neural's neuro symbolic architecture. You have a mix of both.\", tool_call_id='sKGMXCUCQ', name='search', role='tool')]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate response asynchronously\n",
        "response = await client.chat.stream_async(\n",
        "    model=\"mistral-large-latest\",\n",
        "    messages=agent.messages,\n",
        "    tools=agent.tool_signatures,\n",
        "    tool_choice=\"auto\"\n",
        ")\n",
        "# full response object to be built\n",
        "all_tokens = []\n",
        "all_usage = []\n",
        "# iterate through the token generator and add to queue\n",
        "async for chunk in response:\n",
        "    if isinstance((tool_call := chunk.data.choices[0].delta.tool_calls), list):\n",
        "        print(tool_call)\n",
        "    elif (token := chunk.data.choices[0].delta.content) is not None:\n",
        "        print(token, end=\"\", flush=True)\n",
        "        all_tokens.append(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfZzI36Bov6z",
        "outputId": "81174ac9-5fd1-4679-8c7e-36ee9c6ed71d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the article, the term 'symbolic' refers to the traditional approach to artificial intelligence (AI) that was prevalent from the 1940s to the 1960s and possibly into the 1970s. This approach is characterized by the use of written rules, ontologies, and logical functions to achieve true artificial general intelligence (AGI). The symbolists believed that AGI could be attained through these methods, which involved creating philosophical grammars and logical frameworks.\n",
            "\n",
            "An example of symbolic logic is Aristotle's syllogistic logic, which involves a major premise, a minor premise, and a conclusion derived from these premises. For instance, a syllogism might state that all dogs have four legs (major premise), and if a specific animal is a dog (minor premise), then that animal has four legs (conclusion).\n",
            "\n",
            "The article also discusses how neural networks, which are a key component of modern AI, learn logical representations of concepts, somewhat akin to symbols, but these are not handwritten. The combination of neural networks (the neural part) and symbolic methods (the symbolic part) forms what is known as a neurosymbolic architecture. This architecture integrates both approaches, where neural networks can learn and represent concepts, while symbolic methods provide handwritten rules and logical structures.\n",
            "\n",
            "In summary, 'symbolic' in this context refers to the traditional AI approach that relies on handwritten rules and logical frameworks to achieve intelligence."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After adding these additional tool call messages our LLM is able to respond to our query directly. Now let's integrate all of this back into a new `Agent` class."
      ],
      "metadata": {
        "id": "BDWV8-UvpWSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    messages: list[AssistantMessage | SystemMessage | UserMessage]\n",
        "    usage: list[UsageInfo]\n",
        "    tool_signatures: list[Function]\n",
        "    queue: asyncio.Queue | None = None\n",
        "\n",
        "    def __init__(self, tool_signatures: list[Function], max_steps: int = 3):\n",
        "        self.messages = [\n",
        "            SystemMessage(content=(\n",
        "                \"You are an AI expert providing help to the user \"\n",
        "                \"based on the content of the provided transcribed \"\n",
        "                \"document.\"\n",
        "            ))\n",
        "        ]\n",
        "        self.usage = []\n",
        "        self.tool_signatures = tool_signatures\n",
        "        self.max_steps = max_steps\n",
        "\n",
        "    async def chat(self, content: str) -> AssistantMessage:\n",
        "        # append user message to self.messages\n",
        "        self.messages.append(UserMessage(content=content))\n",
        "        # we will need to enter a loop to support multiple iterations\n",
        "        step = 0\n",
        "        while step <= self.max_steps:\n",
        "            # generate response asynchronously\n",
        "            response = await client.chat.stream_async(\n",
        "                model=\"mistral-large-latest\",\n",
        "                messages=self.messages,\n",
        "                tools=self.tool_signatures,\n",
        "                tool_choice=\"auto\"\n",
        "            )\n",
        "            # full response object to be built\n",
        "            all_tokens = []\n",
        "            all_usage = []\n",
        "            # iterate through the token generator and add to queue\n",
        "            async for chunk in response:\n",
        "                if isinstance(\n",
        "                    (tool_calls := chunk.data.choices[0].delta.tool_calls), list\n",
        "                ):\n",
        "                    # print the tool call in a cleaner format\n",
        "                    print(\n",
        "                        f\"{tool_calls[0].function.name}: \"\n",
        "                        f\"{tool_calls[0].function.arguments}\"\n",
        "                    )\n",
        "                    # we execute our tool\n",
        "                    tool_message = await execute_tool(tool_call=tool_calls[0])\n",
        "                    # and add the assistant tool call and tool output message\n",
        "                    # to our self.messages\n",
        "                    self.messages.extend([\n",
        "                        AssistantMessage(content=\"\", tool_calls=tool_calls),\n",
        "                        tool_message\n",
        "                    ])\n",
        "\n",
        "                elif (token := chunk.data.choices[0].delta.content) is not None:\n",
        "                    print(token, end=\"\", flush=True)\n",
        "                    all_tokens.append(token)\n",
        "            # append usage (we can use this later)\n",
        "            self.usage.append(chunk.data.usage)\n",
        "            # append assistant message to self.messages (if returned)\n",
        "            if len(all_tokens) > 1:\n",
        "                self.messages.append(AssistantMessage(content=\"\".join(all_tokens)))\n",
        "                break\n",
        "            step += 1\n",
        "        return self.messages[-1], tool_call"
      ],
      "metadata": {
        "id": "8Q1LKi6WpU5F"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's try another query, this time we will try to allow our agent to use the `search` tool twice to collate information from various chunks."
      ],
      "metadata": {
        "id": "1_QkMXZkDVnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = Agent(tool_signatures=tool_signatures)\n",
        "\n",
        "res = await agent.chat(\n",
        "    content=(\n",
        "        \"Does the document mention 'good old fashioned AI'? And does it \"\n",
        "        \"say anything about deepseek? How does the document \"\n",
        "        \"compare the two?\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoO49sb1Ajen",
        "outputId": "24e96a7e-a0ea-4aec-f9eb-f7464b7041dc"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "search: {\"query\": \"good old fashioned AI\"}\n",
            "Yes, the document does mention the term 'good old fashioned AI.' This term is used to refer to traditional AI approaches, also known as symbolic AI. These methods involve using logical frameworks and symbolic reasoning to build AI systems. The document discusses how this traditional approach aimed to achieve AI through written rules, ontologies, and logical functions.\n",
            "\n",
            "Next, I'll look for mentions of 'deepseek' in the document.search: {\"query\": \"deepseek\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite performing two searches to answer this query, we still used _significantly_ less tokens:"
      ],
      "metadata": {
        "id": "R2T_Fg1GGj0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent.usage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqj1KDlICErf",
        "outputId": "8a743261-75f9-4675-bc19-46b6cde20e10"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[UsageInfo(prompt_tokens=187, completion_tokens=23, total_tokens=210),\n",
              " UsageInfo(prompt_tokens=897, completion_tokens=112, total_tokens=1009)]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without chunking we spent ~$0.12 on a single query (with a single question):"
      ],
      "metadata": {
        "id": "u8XIE_6sGsX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dthl3iGwMnyR",
        "outputId": "1c1fdd45-398c-4180-9eb3-8a0c7c123742"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.01161, 0.01287, 0.01435]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With chunking, for two questions within a single query we're spending:"
      ],
      "metadata": {
        "id": "0izRY9oXM4Dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for usage in agent.usage:\n",
        "    print(f\"${cost(usage=usage)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuEbgTMIGPCs",
        "outputId": "f708d0be-5ee8-4529-88f5-0902512c1154"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$0.00042\n",
            "$0.00202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A total of ~$0.0024, a dramatic six-fold reduction in price."
      ],
      "metadata": {
        "id": "qJFyhuRZMZUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "HODV8EEHNKeD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With that we've built an agent capable of helping us understand videos. We've also taken steps to drastically optimize expenditure."
      ],
      "metadata": {
        "id": "dthGXq8rMDTD"
      }
    }
  ]
}